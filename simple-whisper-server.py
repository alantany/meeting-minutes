#!/usr/bin/env python3
"""
ç®€å•çš„ Whisper è½¬å½•æœåŠ¡
ç”¨äºæ›¿ä»£å¤æ‚çš„ Docker è®¾ç½®ï¼Œç›´æ¥åœ¨ç«¯å£ 8178 æä¾›è½¬å½•æœåŠ¡
"""

import os
import sys
import asyncio
import json
import logging
import tempfile
import subprocess
from pathlib import Path
from typing import Optional, Dict, Any

from fastapi import FastAPI, HTTPException, File, UploadFile, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import whisper

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é…ç½®
WHISPER_PORT = 8178
WHISPER_HOST = "127.0.0.1"
MODEL_DIR = Path(__file__).parent / "models"

# å…¨å±€å˜é‡
whisper_model: Optional[whisper.Whisper] = None

app = FastAPI(
    title="Simple Whisper Transcription Service",
    description="ç®€å•çš„ Whisper è½¬å½•æœåŠ¡",
    version="1.0.0"
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def load_whisper_model(model_name: str = "base.en") -> whisper.Whisper:
    """åŠ è½½ Whisper æ¨¡å‹"""
    global whisper_model
    
    if whisper_model is not None:
        return whisper_model
    
    # å°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹æ–‡ä»¶
    local_model_path = MODEL_DIR / f"ggml-{model_name}.bin"
    
    try:
        if local_model_path.exists():
            logger.info(f"Loading local Whisper model: {local_model_path}")
            # å¯¹äºæœ¬åœ° ggml æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ whisper-cpp æˆ–è€…å›é€€åˆ°æ ‡å‡†æ¨¡å‹
            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æ ‡å‡†çš„ whisper åº“ï¼Œå®ƒä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹
            whisper_model = whisper.load_model(model_name.replace(".en", ""))
        else:
            logger.info(f"Loading Whisper model: {model_name}")
            whisper_model = whisper.load_model(model_name.replace(".en", ""))
        
        logger.info("Whisper model loaded successfully")
        return whisper_model
        
    except Exception as e:
        logger.error(f"Failed to load Whisper model: {e}")
        # å›é€€åˆ°æœ€å°æ¨¡å‹
        try:
            logger.info("Falling back to tiny model")
            whisper_model = whisper.load_model("tiny")
            return whisper_model
        except Exception as e2:
            logger.error(f"Failed to load fallback model: {e2}")
            raise HTTPException(status_code=500, detail=f"Failed to load any Whisper model: {e2}")

@app.get("/")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "service": "whisper-transcription", "port": WHISPER_PORT}

@app.post("/stream")
async def transcribe_audio_stream(audio: UploadFile = File(...)):
    """è½¬å½•éŸ³é¢‘æ–‡ä»¶ - åŒ¹é…å‰ç«¯æœŸå¾…çš„ /stream ç«¯ç‚¹"""
    try:
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        model = load_whisper_model()
        
        # è¯»å–åŸå§‹éŸ³é¢‘æ•°æ®
        content = await audio.read()
        logger.info(f"Received audio data: {len(content)} bytes from {audio.filename}")
        
        # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºf32æ ·æœ¬
        import struct
        samples = []
        for i in range(0, len(content), 4):  # æ¯ä¸ªf32å 4å­—èŠ‚
            if i + 4 <= len(content):
                sample = struct.unpack('<f', content[i:i+4])[0]  # å°ç«¯åºf32
                samples.append(sample)
        
        logger.info(f"Converted to {len(samples)} audio samples")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆWhisperéœ€è¦ï¼‰
        import numpy as np
        audio_array = np.array(samples, dtype=np.float32)
        
        # å¦‚æœéŸ³é¢‘æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ
        if len(audio_array) == 0:
            logger.warning("Empty audio data received")
            return {"segments": [], "buffer_size_ms": 0}
        
        try:
            # ä½¿ç”¨ Whisper è¿›è¡Œè½¬å½•
            logger.info(f"Transcribing {len(audio_array)} audio samples")
            result = model.transcribe(audio_array)
            
            # æ ¼å¼åŒ–ç»“æœä»¥åŒ¹é…å‰ç«¯æœŸå¾…çš„æ ¼å¼
            segments = []
            for segment in result.get("segments", []):
                segments.append({
                    "text": segment.get("text", "").strip(),
                    "t0": segment.get("start", 0.0),
                    "t1": segment.get("end", 0.0)
                })
            
            # è¿”å›å‰ç«¯æœŸå¾…çš„æ ¼å¼
            response = {
                "segments": segments,
                "buffer_size_ms": 0
            }
            
            logger.info(f"Transcription completed: {len(segments)} segments")
            return response
            
        except Exception as transcribe_error:
            logger.error(f"Transcription failed: {transcribe_error}")
            return {"segments": [], "buffer_size_ms": 0}
                
    except Exception as e:
        logger.error(f"Transcription failed: {e}")
        raise HTTPException(status_code=500, detail=f"Transcription failed: {str(e)}")

@app.post("/inference")
async def transcribe_audio_inference(file: UploadFile = File(...)):
    """è½¬å½•éŸ³é¢‘æ–‡ä»¶ - å¤‡ç”¨ç«¯ç‚¹"""
    return await transcribe_audio_stream(file)

@app.websocket("/stream")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket æµå¼è½¬å½•ç«¯ç‚¹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    await websocket.accept()
    logger.info("WebSocket connection established")
    
    try:
        while True:
            # æ¥æ”¶éŸ³é¢‘æ•°æ®
            data = await websocket.receive_bytes()
            
            # ç®€åŒ–å¤„ç†ï¼šå°†æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶å¹¶è½¬å½•
            # å®é™…åº”ç”¨ä¸­åº”è¯¥å®ç°çœŸæ­£çš„æµå¼å¤„ç†
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(data)
                tmp_file_path = tmp_file.name
            
            try:
                model = load_whisper_model()
                result = model.transcribe(tmp_file_path)
                
                # å‘é€è½¬å½•ç»“æœ
                await websocket.send_json({
                    "segments": [
                        {
                            "text": segment.get("text", "").strip(),
                            "t0": segment.get("start", 0.0),
                            "t1": segment.get("end", 0.0)
                        }
                        for segment in result.get("segments", [])
                    ],
                    "buffer_size_ms": 0
                })
                
            finally:
                try:
                    os.unlink(tmp_file_path)
                except:
                    pass
                    
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        logger.info("WebSocket connection closed")

def main():
    """å¯åŠ¨æœåŠ¡"""
    logger.info("=" * 50)
    logger.info("ğŸ¤ Simple Whisper Transcription Service")
    logger.info("=" * 50)
    logger.info(f"Host: {WHISPER_HOST}")
    logger.info(f"Port: {WHISPER_PORT}")
    logger.info(f"Model Directory: {MODEL_DIR}")
    logger.info("=" * 50)
    
    # é¢„åŠ è½½æ¨¡å‹
    try:
        logger.info("Pre-loading Whisper model...")
        load_whisper_model()
        logger.info("âœ… Model loaded successfully")
    except Exception as e:
        logger.error(f"âŒ Failed to load model: {e}")
        logger.info("Service will try to load model on first request")
    
    # å¯åŠ¨æœåŠ¡
    logger.info(f"ğŸš€ Starting server on http://{WHISPER_HOST}:{WHISPER_PORT}")
    logger.info("ğŸ“– API docs: http://127.0.0.1:8178/docs")
    logger.info("ğŸ”— WebSocket: ws://127.0.0.1:8178/stream")
    logger.info("=" * 50)
    
    uvicorn.run(
        app,
        host=WHISPER_HOST,
        port=WHISPER_PORT,
        log_level="info"
    )

if __name__ == "__main__":
    main()
